{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJvV4ZyNcAolNm1C36jyq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliezerkapish/Text-Classifier-Entity-Extractor-and-Summarizer-with-LangGraphi/blob/main/Text_Classifier%2C_Entity_Extractor%2C_and_Summarizer_with_LangGraphi_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to LangGraph By Scoras-Academy"
      ],
      "metadata": {
        "id": "4AUYYcyJTTPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LangGraph is a framework for creating applicaitons using graph-based workflows.\n",
        "#Each node represents a function or computacional step, and the edges define the flow between these nodes based on certain conditions.\n",
        "\n",
        "#Key Featrures:\n",
        "\n",
        "#State Management\n",
        "#Flexible Routing\n",
        "#Persistence\n",
        "#Visualization"
      ],
      "metadata": {
        "id": "bWt0sILDThkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tutorial Overview: Text Analysis Pipeline"
      ],
      "metadata": {
        "id": "0A1uj5VOVmJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In this tutorial, we will demonstrate the power of LangGraph by building a multi-step text analysis pipeline.\n",
        "# Our use case will focus on processing a given text through three main stages:\n",
        "\n",
        "#Text Classification: We will categorize the input text into predefined categories (e.g., News, Blog, Research, or Other).\n",
        "\n",
        "#Entity Extraction: We will identify and extract key entities such as people, organizations, and places from the text.\n",
        "\n",
        "#Text Summarization: Finally, we will generate a concise summary of the input text."
      ],
      "metadata": {
        "id": "nqWYlx4DVn_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This pipeline showcases how LangGraph can be used to create a modular and extensible workflow for natural language processing tasks.\n",
        "#By the end of this tutorial, you will understand how to build a graph-based application that can be easily modified or expanded for various text analysis needs."
      ],
      "metadata": {
        "id": "gyuczr91WNiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "smsRStuBWh-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell imports all the modules and classes necessary for our LangGraph tutorial."
      ],
      "metadata": {
        "id": "iIpGnUtrWkwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "\n",
        "# Install required libraries\n",
        "!pip install langgraph\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install langchain_openai\n",
        "\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "from typing import TypedDict, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from IPython.display import display, Image\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Imports for system manipulation and types\n",
        "# Imports from LangGraph for creating the state graph\n",
        "# Imports from LangChain for prompts, language models, and messages\n",
        "# Import for graph visualization\n",
        "# Imports for Jupyter display\n",
        "# Import for loading environment variables"
      ],
      "metadata": {
        "id": "j0BaCteLWqhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16823eed-fb67-4350-87f0-18fc35a1900d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.44-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
            "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.35-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.137)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
            "Collecting httpx-sse>=0.4.0 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.2)\n",
            "Downloading langgraph-0.2.44-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.35-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: httpx-sse, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.13\n",
            "    Uninstalling langchain-core-0.3.13:\n",
            "      Successfully uninstalled langchain-core-0.3.13\n",
            "Successfully installed httpx-sse-0.4.0 langchain-core-0.3.15 langgraph-0.2.44 langgraph-checkpoint-2.0.2 langgraph-sdk-0.1.35\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.15)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.52.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.1.137)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.5-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.2.5 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a .env File"
      ],
      "metadata": {
        "id": "FzQjdccXhw_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Set the file path to your API key file in Google Drive\n",
        "# Update the path if necessary\n",
        "file_path = \"/content/drive/MyDrive/OPENAI_API_KEY.txt\"\n",
        "\n",
        "# Step 3: Read the API key from the .txt file\n",
        "with open(file_path, \"r\") as file:\n",
        "    api_key = file.read().strip()  # Remove any extra whitespace\n",
        "\n",
        "# Step 4: Create a .env file and write the API key into it\n",
        "with open(\".env\", \"w\") as env_file:\n",
        "    env_file.write(f\"OPENAI_API_KEY={api_key}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PunWO6Hvh4jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714786d8-9f74-46c5-86ab-f39d984e4fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the API Key"
      ],
      "metadata": {
        "id": "fawuTjJ2W9Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell loads the environment variables and sets up the OpenAI API key. Make sure you have a .env file with your OPENAI_API_KEY."
      ],
      "metadata": {
        "id": "aZlPA5sPXDVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set up the OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "KH5TQJErXWf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensure API Key is Loaded Correctly"
      ],
      "metadata": {
        "id": "QSi6vHngm2S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(\"API Key Loaded:\", api_key is not None)"
      ],
      "metadata": {
        "id": "1xeKKpY3m39B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f2dd75-c386-4514-8c58-2eb55bafe3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key Loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Text Processing Pipeline"
      ],
      "metadata": {
        "id": "fN6Tp2SwXqNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define State and Initialize LLM"
      ],
      "metadata": {
        "id": "9E4Xi2hpX1Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here, we define the State class to store the data for our workflow and initialize the ChatOpenAI model."
      ],
      "metadata": {
        "id": "euSG2lsrX-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    text: str\n",
        "    classification: str\n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "Azx7LvZHYLs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Node Functions"
      ],
      "metadata": {
        "id": "-mybob8QYScV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#These functions define the operations performed at each node of our graph: classification, entity extraction, and summarization"
      ],
      "metadata": {
        "id": "2RYtyG30YZJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_node(state: State):\n",
        "    ''' Classifies the text into one of the categories: News, Blog, Research, or Other '''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText:{text}\\n\\nCategory:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    classification = llm.predict_messages([message]).content.strip()\n",
        "    return {\"classification\": classification}\n",
        "\n",
        "\n",
        "def entity_extraction_node(state: State):\n",
        "    ''' Extracts all entities (Person, Organization, Location) from the text '''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Extract all entities (Person, Organization, Location) from the following text. Provide the result as a comma-separated list.\\n\\nText:{text}\\n\\nEntities:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    entities = llm.predict_messages([message]).content.strip().split(\", \")\n",
        "    return {\"entities\": entities}\n",
        "\n",
        "\n",
        "def summarization_node(state: State):\n",
        "    ''' Summarizes the text in a short sentence '''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Summarize the following text in a short sentence.\\n\\nText:{text}\\n\\nSummary:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    summary = llm.predict_messages([message]).content.strip()\n",
        "    return {\"summary\": summary}"
      ],
      "metadata": {
        "id": "rlbWhi7DYmIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Tools and Build Workflow"
      ],
      "metadata": {
        "id": "jGAE53v1YsfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell builds the StateGraph workflow."
      ],
      "metadata": {
        "id": "qKGfTAJnmEqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"classification_node\", classification_node)\n",
        "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add edges to the graph\n",
        "workflow.set_entry_point(\"classification_node\")  # Set the graph entry point\n",
        "workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "workflow.add_edge(\"summarization\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "N77WRAVFY5OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Tools and Build Workflow"
      ],
      "metadata": {
        "id": "IcKgrFp_Zbor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell builds the StateGraph workflow."
      ],
      "metadata": {
        "id": "YVk2RLbjZc1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"classification_node\", classification_node)\n",
        "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add edges to the graph\n",
        "workflow.set_entry_point(\"classification_node\")  # Set the graph entry point\n",
        "workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "workflow.add_edge(\"summarization\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "QXpDU1U5Zk4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the Workflow"
      ],
      "metadata": {
        "id": "thMZBA1tZ339"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell creates a visual representation of our workflow using Mermaid."
      ],
      "metadata": {
        "id": "GsC239LAZ42n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(\n",
        "    Image(\n",
        "        app.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "7L1oMubsZ_7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "8a484fab-9478-4fa2-ea29-9fb33f7256be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the Pipeline"
      ],
      "metadata": {
        "id": "QXG7KtpDaIUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell runs a sample text through our pipeline and displays the results."
      ],
      "metadata": {
        "id": "NBCKIbduaZfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"\n",
        "Post do Linkedin Influencer Samuel Fernando: Quase todos os dias eu recebo mensagem com perguntas do que eu recomendo de cursos e formação em GenAI/LLM.\n",
        "\n",
        "Eu tenho uma opinião muito forte sobre todos os cursos, imersões e essas coisas de \"formação de IA para executivos\" oferecidos por influenciadores famosos, .\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "state_input = {\"text\": sample_text}\n",
        "result = llm.invoke([sample_text]).content.strip()\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"\\nEntities:\", result[\"entities\"])\n",
        "print(\"\\nSummary:\", result[\"summary\"])"
      ],
      "metadata": {
        "id": "tqYgC-jSabTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "6064de0b-e5ba-4732-d74e-b04948683911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-98b68e26fa6f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstate_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classification:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    813\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    }
  ]
}